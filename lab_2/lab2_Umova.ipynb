{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Лабораторна робота 2. Базові алгоритми прогнозування та GEO візуалізація**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мета роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана лабораторна робота присвячена вивченню базових алгоритмів аналізу великих обсягів даних на прикладі поширення COVID-19 у світі. Буде розглянуто прогнозування на основі лінійної регресії, obtain staistics and та створення інтерактивної карти, що показує динаміку поширення вірусу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Виконання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Сьогодні існує багато відкритих даних про поширення COVID-19 у світі. Однак представлено небагато інструментів для прогнозування та візуалізації цих процесів. Ця лабораторна робота покаже, як ви можете завантажувати дані з відкритих джерел, виконувати попередній аналіз даних, перетворювати та очищати дані, обчислювати кореляцію та аналізувати лаги.\n",
    "\n",
    "Далі будуть розглянуті 2 різні математичні підходи до розрахунку прогнозу на основі лінійної регресії.\n",
    "\n",
    "Для цього буде продемонстровано поділ набору даних на навчальні та тестові набори. Буде показано, як будувати моделі за допомогою двох різних фреймворків. Наступним кроком є побудова прогнозу та аналіз точності та адекватності отриманих моделей.\n",
    "\n",
    "Наприкінці лабораторної роботи буде продемонстровано, як візуалізувати динаміку поширення COVID -інфекції на інтерактивних картах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Матеріали та методи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "У цій лабораторіній роботі ми вивчимо основні методи прогнозування часових рядів та їх візуалізації на інтерактивних картах. Лабораторна робота складається з трьох етапів:\n",
    "\n",
    "1. Завантаження та попередній аналіз даних\n",
    "2. Прогнозування\n",
    "3. Інтерактивні карти\n",
    "\n",
    "На першому етапі  завантажуємо дані та реалізуємо підготовку даних до аналізу:\n",
    "* завантажити дані\n",
    "* змінити типи даних стовпців\n",
    "* групування даних\n",
    "* перетворення набору даних\n",
    "* усунення відсутніх даних\n",
    "\n",
    "На етапі прогнозування будуть продемонстровані методи побудови та встановлення моделей, автоматизація розрахунку статистичної інформації, зокрема:\n",
    "* вибір гіпотез \n",
    "* розбиття набору даних на навчальні та тестові вибірки\n",
    "* побудова моделі за допомогою 2 різних фреймворків\n",
    "* розрахунок основних статистичних показників\n",
    "* прогнозування часових рядів\n",
    "\n",
    "At the stage of interactive maps the build will show how to display statistical information on interactive maps:\n",
    "* data transformation for mapping\n",
    "* downloads polygons of maps\n",
    "* building of interactive maps\n",
    "На етапі інтерактивних карт навчимося, як відображати статистичну інформацію на інтерактивних картах:\n",
    "* перетворення даних для відображення\n",
    "* завантаження полігону карт\n",
    "* створення інтерактивних карт\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvG7RdB0hTZf"
   },
   "source": [
    "Статистичні дані отримані з https://ourworldindata.org/coronavirus на основі Creative Commons BY license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Середовища виконання\n",
    "* Python,\n",
    "* [Pandas,](https://pandas.pydata.org)\n",
    "* [SeaBorn,](https://seaborn.pydata.org)\n",
    "* Statistics,\n",
    "* [Plotly](https://plotly.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отримані навики "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Після виконання даної лабораторної роботи отримуються навики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Завантаження даних з  *.csv файлів\n",
    "* Автоматична зміна даних \n",
    "* Перетворення таблиці даних\n",
    "* Візуалізація даних на основі pandas and seaborn\n",
    "* Побудова прогнозу \n",
    "* Побудова інтерактивних карт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завантаження та попередній аналіз даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Завантаження даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перш ніж розпочати, деякі бібліотеки потрібно імпортувати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наступним кроком є завантаження даних файлу з відкритого сховища, створеного компанією [ Our World in Data з використанням  Creative Commons BY license](https://ourworldindata.org/coronavirus) by the **[read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zvit_date</th>\n",
       "      <th>registration_area</th>\n",
       "      <th>registration_region</th>\n",
       "      <th>registration_settlement</th>\n",
       "      <th>registration_settlement_lng</th>\n",
       "      <th>registration_settlement_lat</th>\n",
       "      <th>new_susp</th>\n",
       "      <th>new_confirm</th>\n",
       "      <th>active_confirm</th>\n",
       "      <th>new_death</th>\n",
       "      <th>new_recover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2020</td>\n",
       "      <td>Донецька</td>\n",
       "      <td>Мангушський район</td>\n",
       "      <td>Мелекіне</td>\n",
       "      <td>37.394099</td>\n",
       "      <td>46.957301</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/7/2020</td>\n",
       "      <td>Донецька</td>\n",
       "      <td>Краматорськ</td>\n",
       "      <td>Краматорськ</td>\n",
       "      <td>37.584350</td>\n",
       "      <td>48.738967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/12/2020</td>\n",
       "      <td>Запорізька</td>\n",
       "      <td>Запоріжжя</td>\n",
       "      <td>Запоріжжя</td>\n",
       "      <td>35.139567</td>\n",
       "      <td>47.838800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/19/2020</td>\n",
       "      <td>Закарпатська</td>\n",
       "      <td>Берегівський район</td>\n",
       "      <td>Берегуйфалу</td>\n",
       "      <td>22.807531</td>\n",
       "      <td>48.279628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/22/2020</td>\n",
       "      <td>Донецька</td>\n",
       "      <td>Українськ</td>\n",
       "      <td>Українськ</td>\n",
       "      <td>37.362549</td>\n",
       "      <td>48.096803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Черкаська</td>\n",
       "      <td>Уманський район</td>\n",
       "      <td>Краснопілка</td>\n",
       "      <td>30.249593</td>\n",
       "      <td>48.860909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Черкаська</td>\n",
       "      <td>Уманський район</td>\n",
       "      <td>Вільшана-Слобідка</td>\n",
       "      <td>30.453567</td>\n",
       "      <td>48.609810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Черкаська</td>\n",
       "      <td>Шполянський район</td>\n",
       "      <td>Мар'янівка</td>\n",
       "      <td>31.464540</td>\n",
       "      <td>49.020017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Черкаська</td>\n",
       "      <td>Драбівський район</td>\n",
       "      <td>Погреби</td>\n",
       "      <td>32.192496</td>\n",
       "      <td>50.093403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>12/3/2020</td>\n",
       "      <td>Черкаська</td>\n",
       "      <td>Лисянський район</td>\n",
       "      <td>Смільчинці</td>\n",
       "      <td>30.835816</td>\n",
       "      <td>49.191314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         zvit_date registration_area registration_region  \\\n",
       "0         1/1/2020          Донецька   Мангушський район   \n",
       "1         1/7/2020          Донецька         Краматорськ   \n",
       "2        1/12/2020        Запорізька           Запоріжжя   \n",
       "3        1/19/2020      Закарпатська  Берегівський район   \n",
       "4        1/22/2020          Донецька           Українськ   \n",
       "...            ...               ...                 ...   \n",
       "1048570  12/3/2020         Черкаська     Уманський район   \n",
       "1048571  12/3/2020         Черкаська     Уманський район   \n",
       "1048572  12/3/2020         Черкаська   Шполянський район   \n",
       "1048573  12/3/2020         Черкаська   Драбівський район   \n",
       "1048574  12/3/2020         Черкаська    Лисянський район   \n",
       "\n",
       "        registration_settlement  registration_settlement_lng  \\\n",
       "0                      Мелекіне                    37.394099   \n",
       "1                   Краматорськ                    37.584350   \n",
       "2                     Запоріжжя                    35.139567   \n",
       "3                   Берегуйфалу                    22.807531   \n",
       "4                     Українськ                    37.362549   \n",
       "...                         ...                          ...   \n",
       "1048570             Краснопілка                    30.249593   \n",
       "1048571       Вільшана-Слобідка                    30.453567   \n",
       "1048572              Мар'янівка                    31.464540   \n",
       "1048573                 Погреби                    32.192496   \n",
       "1048574              Смільчинці                    30.835816   \n",
       "\n",
       "         registration_settlement_lat  new_susp  new_confirm  active_confirm  \\\n",
       "0                          46.957301         0            0               0   \n",
       "1                          48.738967         0            0               0   \n",
       "2                          47.838800         0            0               0   \n",
       "3                          48.279628         0            0               0   \n",
       "4                          48.096803         0            0               0   \n",
       "...                              ...       ...          ...             ...   \n",
       "1048570                    48.860909         0            0               1   \n",
       "1048571                    48.609810         0            0               1   \n",
       "1048572                    49.020017         0            0               2   \n",
       "1048573                    50.093403         1            0               4   \n",
       "1048574                    49.191314         0            0               1   \n",
       "\n",
       "         new_death  new_recover  \n",
       "0                1            0  \n",
       "1                1            0  \n",
       "2                1            0  \n",
       "3                1            0  \n",
       "4                1            0  \n",
       "...            ...          ...  \n",
       "1048570          0            0  \n",
       "1048571          0            0  \n",
       "1048572          0            0  \n",
       "1048573          0            0  \n",
       "1048574          0            0  \n",
       "\n",
       "[1048575 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_word = pd.read_csv('Lab2_data.csv')\n",
    "covid_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Розглянемо отриманий набір даних. Як бачимо, набір даних складається з 86202 рядків × 59 стовпців. Перші 3 стовпці - Геоінформація. 4 колонка - дата вимірювання. Ще 55 - дані Covid. Також у DataSet спостерігаються деякі відсутні дані. Ми повинні бути впевнені, що python правильно розпізнав типи даних. Для цього нам слід використовувати **[pandas.info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html?highlight=info#pandas.DataFrame.info)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_word.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо, 54 стовпці даних Covid прочитано належним чином (float64). Перші 4 стовпці та test_units були розпізнані як: об’єкти. Давайте дослідимо їх:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['iso_code', 'continent', 'location', 'tests_units']\n",
    "covid_word[fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_word['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зміна типи даних стовпців"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бачимо, що колонки: 'iso_code', 'continent', 'location', 'tests_units' мають багато повторів і повинні бути віднесені до категорійних полів **([pandas.astype()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html?highlight=astype#pandas.DataFrame.astype))**.\n",
    "Поле 'data' -необхідно конвертувати у DataTime type **([pandas.to_datetime()](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html))**. Щоб побачити результати, використаємо**[pandas.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html?highlight=describe#pandas.DataFrame.describe)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['iso_code', 'continent', 'location', 'tests_units']\n",
    "covid_word[fields] = covid_word[fields].astype('category')\n",
    "covid_word.loc[:, 'date'] = pd.to_datetime(covid_word['date'])\n",
    "covid_word[fields].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набір даних містить інформацію про 6 континентів та про 219 країн. Поле 'tests_units' містить 4 категорії. Щоб показати це,  можна використовувати **[pandas.Series.cat.categories](https://pandas.pydata.org/docs/reference/api/pandas.Series.cat.categories.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_word['tests_units'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Групування даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визначимо, скільки записів кожної категорії є в наборі даних **[pandas.Series.value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)** та покажемо результат у таблиці **[pandas.Series.to_frame()](https://pandas.pydata.org/docs/reference/api/pandas.Series.to_frame.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_word['tests_units'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як показано вище, набір даних містить 54 статистичних поля, які можна використовувати для будь -якого аналізу. Для простоти виберем найбільш інформативне - **total cases**. Давайте визначимо, скільки хворих належить до кожної з категорій,  використовуючи\n",
    " **[pandas.DataFrame.groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html?highlight=groupby#pandas.DataFrame.groupby)** та сортуючи у порядку спадання. **[pandas.DataFrame.sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_word.groupby('tests_units')['total_cases'].sum().sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для зручності відображення даних з плаваючою комою можна вказати загальний формат виводу  DataFrame за допомогою **[pandas.options.display.float_format](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html)**. Ці налаштування будуть активними протягом усього сеансу  використаня бібліотеки pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "covid_word.groupby('tests_units')['total_cases'].sum().sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Як бачимо, найбільша кількість хворих належить до категорії \"samples tested\". Переходимо до наступного кроку "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перетворення набору даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо передбачити поширення COVID-19 на різних континентах. Для цього нам потрібно перетворити наш набір даних. Зокрема, як індексне поле для використання дат вимірювання, так і як стовпці повинні бути дані про загальну кількість випадків залежно від континенту. Для цього слід використати зведену таблицю: **[pivot_table()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot_table.html?highlight=pivot_table#pandas.DataFrame.pivot_table)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covid = pd.pivot_table(covid_word, values= 'total_cases', index= ['date'], columns=['continent'], aggfunc='sum', margins=False)\n",
    "p_covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми створили новий набір даних, який буде використовуватися для прогнозування. Давайте візуалізуємо ці дані за допомогою **[pandas.DataFrame.plot()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html?highlight=plot#pandas.DataFrame.plot)**.  Слід зазначити, що pandas інкапсулює matplotlib бібліотеку та наслідує функцію  plot(). Тому для коректного відображення бібліотеку matplotlib необхідно імпортувати та застосувати функцію **[matplotlib.pyplot.show()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.show.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covid.plot()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Усунення відсутніх даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Як бачимо, на графіку правильно відображаються відсутні дані. Однак не всі математичні методи коректно працюють з такими даними. Тому необхідно усунути всі пропущені дані. У нашому випадку достатньо видалити рядки, що їх містять, за допомогою функції **[pandas.DataFrame.dropna()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covid = p_covid.dropna()\n",
    "p_covid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вибір гіпотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перш ніж будувати прогноз, необхідно спочатку визначити цільове (вихідне) поле, для якого буде побудований прогноз. Наступним кроком є створення гіпотези, яка передбачає визначення вхідних полів, від яких залежить прогноз. Спробуємо спрогнозувати загальну кількість випадків зараження африканців. Ми можемо запропонувати дві гіпотези:\n",
    "\n",
    "1. Загальна кількість випадків зараження африканців залежить від загальної кількості випадків на інших континентах.\n",
    "2. Загальна кількість випадків зараження африканців не залежить від загальної кількості випадків на інших континентах .\n",
    "\n",
    "Щоб перевірити першу гіпотезу, нам слід провести кореляційний аналіз за допомогою**[pandas.DataFrame.corr()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html?highlight=corr#pandas-dataframe-corr)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "p_covid.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кожна клітинка містить коефіцієнти кореляції між двома стовпцями. Тому елементи діагоналі рівні одиниці. Як видно зі стовпця Африки (або рядка), усі коефіцієнти кореляції більше 0,9. Це може бути підтвердженням першої гіпотези. Коефіцієнти кореляції, близькі до одиниці, означають  сильну лінійну залежність між полями. Тому для перевірки першої гіпотези зручно використовувати лінійні моделі."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розбиття набору даних на навчальні та тестові вибірки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для встановлення та перевірки моделі необхідно розділити набір даних на навчальні та тестові набори. Можна реалізувати це за допомогою класичних інструментів Python, таких як зрізи, або скористатися спеціальною функцією, яка має багато гнучких налаштувань (**[sklearn.model_selection.train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)**).\n",
    "За тестовий набір  візьмемо 30% загальних даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_train_test = 0.7\n",
    "l = int(proportion_train_test * len(p_covid))\n",
    "col = p_covid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slises:\n",
    "X_train, X_test, y_train, y_test = p_covid[col[1:]][:l], p_covid[col[1:]][l:], p_covid[col[0]][:l], p_covid[col[0]][l:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click <b>here</b> for the solution</summary> \n",
    "p_covid[col[1:]][:l], p_covid[col[1:]][l:], p_covid[col[0]][:l], p_covid[col[0]][l:]\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn function\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(p_covid[col[1:]], p_covid[col[0]], test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Створення моделей за допомогою sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для побудови лінійної моделі необхідно створити саму лінійну модель, підігнати її, протестувати та зробити прогноз. Для цього використаємо **[sklearn.linear_model.LinearRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_test = regressor.predict(X_test)\n",
    "y_pred_train = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Розрахунок основних статистичних показників"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "є у **y_pred_test** та **y_pred_train** змінних. Після цього ми можемо перевірити адекватність та точність моделі за допомогою **[sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)**. Також ми можемо отримати параметри лінійної моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Correlation train\", regressor.score(X_train, y_train))\n",
    "print(\"Correlation test\", regressor.score(X_test, y_test))\n",
    "print(\"Coefficients:\", regressor.coef_)\n",
    "# pair the feature names with the coefficients\n",
    "print('Pair the feature names with the coefficients:')\n",
    "for s in zip(col[1:], regressor.coef_):\n",
    "    print(s[0], \":\", s[1])\n",
    "print(\"Intercept\", regressor.intercept_)\n",
    "print('Mean Absolute Error (train):', metrics.mean_absolute_error(y_train, y_pred_train))\n",
    "print('Mean Absolute Error (test):', metrics.mean_absolute_error(y_test, y_pred_test))\n",
    "print('Mean Squared Error (train):', metrics.mean_squared_error(y_train, y_pred_train))\n",
    "print('Mean Squared Error (test):', metrics.mean_squared_error(y_test, y_pred_test))\n",
    "print('Root Mean Squared Error (train):', np.sqrt(metrics.mean_squared_error(y_train, y_pred_train)))\n",
    "print('Root Mean Squared Error (test):', np.sqrt(metrics.mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Створення моделей за допомогою statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо,  є велика різниця в точності між  результатами тестування для навчальної та тестової вибірки. Це означає, що ця гіпотеза не правильна. Також ця структура не може генерувати зведений звіт. Для цього можемо використовувати **[statsmodels.api](https://www.statsmodels.org/stable/index.html)** framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n",
    "y_pred_test_OLS = results.predict(X_test)\n",
    "y_pred_train_OLS = results.predict(X_train)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо, у цій структурі використовуються ті ж принципи для створення та підгонки моделей. Це дозволяє складати зведений звіт, а також можна отримати всі інші коефіцієнти статистики таким же чином:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('coefficient of determination:', results.rsquared)\n",
    "print('adjusted coefficient of determination:', results.rsquared_adj)\n",
    "print('regression coefficients:', results.params, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необхідно об'єднати результати, щоб порівняти ці дві моделі **[pandas.DataFrame.join()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({'Actual_test': y_test, 'Predicted_test': y_pred_test, 'Predicted_test_OLS': y_pred_test_OLS})\n",
    "df_train = pd.DataFrame({'Actual_train': y_train, 'Predicted_train': y_pred_train, 'Predicted_train_OLS': y_pred_train_OLS})\n",
    "df = df_train.join(df_test, how='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Як бачимо, pandas автоматично приєднує і впорядковує дані відповідно відповідно до поля індексу. Тому дуже важливо перевірити тип даних поля індексу, особливо, коли  маємо справу з часовим полем ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте візуалізуємо дані"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ви можете бачити, що результати цих двох моделей однакові. Ви також можете побачити, що прогнозування на тестовій вибірці не є ідеальним. Ми можемо подивитися різницю між прогнозними та реальними даними використавши**[seaborn.pairplot()](https://seaborn.pydata.org/generated/seaborn.pairplot.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df_test, x_vars=['Actual_test'], y_vars='Predicted_test',  kind='reg', height = 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значення реальних даних наносяться на горизонтальну вісь, а передбачені - на вертикальну. Чим ближче точки результату до діагоналі, тим краще прогноз моделі. Цей графік підтверджує наш висновок, про поганий прогноз відповідно до цієї гіпотези.\n",
    "Більше того, щоб зробити прогноз на майбутнє, ви повинні знати майбутні дані для іншого континенту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прогнозування часових рядів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спробуємо перевірити другу гіпотезу. Відповідно до цього, потрібно враховувати лише один часовий ряд. У нашому випадку - Африка. Єдине припущення, яке можна зробити - дані на сьогодні залежать від значень попередніх днів. Щоб перевірити наявність залежностей, необхідно провести кореляційний аналіз між ними. Для цього потрібно:\n",
    "1. дублювати часові ряди даних і переміщати їх вертикально вниз на певну кількість днів (lag)\n",
    "2. видалити відсутні дані на початку та в кінці (вони формуються вертикальним зсувом) \n",
    "(**[pandas.DataFrame.shift()])(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shift.html)**\n",
    "3. обчислити коефіцієнт кореляції між отриманими рядами\n",
    "\n",
    "Оскільки цю операцію необхідно виконувати для різних значень відставання, зручно створити окрему функцію:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_correlation_ts(y, x, lag):\n",
    "    \"\"\"\n",
    "    Lag correlation для 2 DateSeries\n",
    "    :param y: fixed\n",
    "    :param x: shifted\n",
    "    :param lag: lag for shifting\n",
    "    :return: DataFrame of lags correlation coefficients\n",
    "    \"\"\"\n",
    "    r = [0] * (lag + 1)\n",
    "    y = y.copy()\n",
    "    x = x.copy()\n",
    "    y.name = \"y\"\n",
    "    x.name = \"x\"\n",
    "\n",
    "    for i in range(0, lag + 1):\n",
    "        ds = y.copy().to_frame()\n",
    "        ds = ds.join(x.shift(i), how='outer')\n",
    "        r[i] = ds.corr().values[0][1]\n",
    "    r = pd.DataFrame(r)\n",
    "    r.index.names = ['Lag']\n",
    "    r.columns = ['Correlation']\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = p_covid[col[0]]\n",
    "y_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестуймо 30 -денний лаг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "l = pd.DataFrame(lag_correlation_ts(y_dataset, y_dataset, 30))\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the time series data is very much dependent on the data of the previous period. Even between 30 days ago, there is a close linear relationship.\n",
    "\n",
    "To build a linear model of type input - target, the target must be the data of the original time series, and the input values are given for the previous days.\n",
    "\n",
    "To automate this process, let's create a universal time series transformation function to a dataset structure.\n",
    "Як бачимо, дані часових рядів дуже сильно залежать від даних попереднього періоду. Навіть між минулими 30 днями  існує тісна лінійна залежність.\n",
    "\n",
    "Щоб побудувати лінійну модель типу input - target, ціллю мають бути дані вихідного часового ряду, а вхідні значення наведені за попередні дні.\n",
    "\n",
    "Щоб автоматизувати цей процес, давайте створимо універсальну функцію перетворення часових рядів у структуру набору даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(in_data, tar_data, n_in=1, dropnan=True, target_dep=False):\n",
    "    \"\"\"\n",
    "    Transformation into a training sample taking into account the lag\n",
    "     : param in_data: Input fields\n",
    "     : param tar_data: Output field (single)\n",
    "     : param n_in: Lag shift\n",
    "     : param dropnan: Do destroy empty lines\n",
    "     : param target_dep: Whether to take into account the lag of the input field If taken into account, the input will start with lag 1\n",
    "     : return: Training sample. The last field is the source\n",
    "    \"\"\"\n",
    "\n",
    "    n_vars = in_data.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    # for i in range(n_in, -1, -1):\n",
    "    if target_dep:\n",
    "        i_start = 1\n",
    "    else:\n",
    "        i_start = 0\n",
    "    for i in range(i_start, n_in + 1):\n",
    "        cols.append(in_data.shift(i))\n",
    "        names += [('%s(t-%d)' % (in_data.columns[j], i)) for j in range(n_vars)]\n",
    "\n",
    "    if target_dep:\n",
    "        for i in range(n_in, -1, -1):\n",
    "            cols.append(tar_data.shift(i))\n",
    "            names += [('%s(t-%d)' % (tar_data.name, i))]\n",
    "    else:\n",
    "        # put it all together\n",
    "        cols.append(tar_data)\n",
    "        # print(tar_data.name)\n",
    "        names.append(tar_data.name)\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = series_to_supervised(pd.DataFrame(y_dataset), y_dataset, 30)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачите, перший і останній стовпці містять однакові цільові дані. Тому, подібно до попередньої моделі, ми будемо формувати навчальні та тестові набори даних, підбирати та порівнювати результати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_2 = dataset.columns\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(dataset[col_2[1:-2]], dataset[col_2[-1]], test_size=0.3, shuffle=False)\n",
    "regressor2 = LinearRegression()\n",
    "regressor2.fit(X_train_2, y_train_2)\n",
    "y_pred_test_2 = regressor2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation train\", regressor2.score(X_train_2, y_train_2))\n",
    "print(\"Correlation test\", regressor2.score(X_test_2, y_test_2))\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test_2, y_pred_test_2))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test_2, y_pred_test_2))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test_2, y_pred_test_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо, результати прогнозу набору тестових даних набагато кращі, ніж у попередній моделі. Давайте візуалізуємо ці 2 результати:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_2 = pd.DataFrame(y_pred_test_2, columns = ['Predicted_test time series'])\n",
    "y_pred_test_2.index = y_test_2.index\n",
    "df_2 = pd.DataFrame({'Actual_test': y_test, 'Predicted_test': y_pred_test, })\n",
    "df_2 = df_2.join(y_pred_test_2, how='outer')\n",
    "df_2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як бачимо, друга модель продукує ідеальний прогноз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Інтерактивні мапи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перетворення даних для  mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зручно відобразити поширення вірусної інфекції на карті, щоб це візуалізувати. Для цього існує кілька бібліотек. Зручно користуватися бібліотекою **[plotly.express](https://plotly.com/python/plotly-express/)** для відображення динаміки COVID-19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побудуємо динаміку поширення COVID-19 (загальна кількість випадків) для європейських країн. Щоб зробити це:\n",
    ":\n",
    "1. Відфільтруйте початковий набір даних, щоб залишити лише європейські країни .\n",
    "2. Залиште колонки тільки з необхідними даними GEO o (\"location\", \"date\", \"total_cases\") відсортованими за \"location\" та \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_EU = covid_word[covid_word.continent == \"Europe\"]\n",
    "covid_EU = covid_EU[[\"location\", \"date\", \"total_cases\"]].sort_values([\"location\", \"date\"])\n",
    "covid_EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед візуалізацією ми повинні видалити дані NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_confirmed_EU = covid_EU[np.isnan(covid_EU.total_cases) == False]\n",
    "modified_confirmed_EU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми повинні змінити тип стовпця total_cases на int64, щоб виправити  порівняння кольорів карти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'total_cases'\n",
    "modified_confirmed_EU.loc[:, c] = modified_confirmed_EU[c].astype('int64')\n",
    "modified_confirmed_EU.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте згрупуємо дані за країнами. \n",
    "Для кожної країни рядки мають бути впорядковані за датою вимірювання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_confirmed_EU=modified_confirmed_EU.set_index('date').groupby('location')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як ми бачимо, DataSet складається з 20052 рядків. Це занадто багато для картографування GEO. Нам потрібно скоротити їх кількість. Наприклад, відображати не по днях, а по тижнях. Для цього вам потрібно скористатися функцією**[pandas.DataFrame.resample()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_confirmed_EU = modified_confirmed_EU.resample('W-MON').sum()\n",
    "print(modified_confirmed_EU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для коректного відображення на карті нам потрібно відновити дані в полі \"location\" та дублювати поле \"Data\", перетворивши їх на тип даних str. Це необхідно для правильного відображення дат інтерактивної карти на смузі прокрутки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_confirmed_EU.loc[:,'location'] = modified_confirmed_EU.index.get_level_values(0)\n",
    "modified_confirmed_EU.loc[:,'Date'] = modified_confirmed_EU.index.get_level_values(1).astype('str')\n",
    "\n",
    "print(modified_confirmed_EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_word=pd.read_csv('owid-covid-data.csv')\n",
    "# c = 'continent'\n",
    "# covid_word.loc[:, c] = covid_word[c].astype('category')\n",
    "# print(covid_word[c])\n",
    "\n",
    "# covid_EU = covid_word[covid_word.continent == \"Europe\"]\n",
    "# covid_EU = covid_EU[[\"location\", \"date\", \"total_cases\"]].sort_values([\"location\", \"date\"])\n",
    "# modified_confirmed_EU = covid_EU[np.isnan(covid_EU.total_cases) == False]\n",
    "# c = 'total_cases'\n",
    "# modified_confirmed_EU.loc[:, c] = modified_confirmed_EU[c].astype('int64')\n",
    "\n",
    "# c = 'date'\n",
    "# c2 = 'Date'\n",
    "# modified_confirmed_EU.loc[:, c2] = pd.to_datetime(modified_confirmed_EU[c])\n",
    "\n",
    "\n",
    "# modified_confirmed_EU=modified_confirmed_EU.set_index('Date').groupby('location')\n",
    "# print(modified_confirmed_EU)\n",
    "# modified_confirmed_EU = modified_confirmed_EU.resample('W-MON').sum()\n",
    "\n",
    "\n",
    "# c = 'Date'\n",
    "# modified_confirmed_EU = modified_confirmed_EU[modified_confirmed_EU[c] >= pd.Timestamp(2021, 1, 1)]\n",
    "# modified_confirmed_EU = modified_confirmed_EU.resample\n",
    "# print(modified_confirmed_EU)\n",
    "# modified_confirmed_EU.loc[:,'location'] = modified_confirmed_EU.index.get_level_values(0)\n",
    "# modified_confirmed_EU.loc[:,'date'] = modified_confirmed_EU.index.get_level_values(1).astype('str')\n",
    "\n",
    "# print(modified_confirmed_EU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Завантаження полігонів карти "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наступним кроком є завантаження полігонів карти. Вони є загальнодоступними: https://data.opendatasoft.com/explore/dataset/european-union-countries%40public/information/\n",
    "Також на цьому сайті представлені схеми набору даних.\n",
    "Ви можете побачити, що ключ \"NAME\" цього json підключено до поля \"location\" у нашому наборі даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"european-union-countries.geojson\", encoding=\"utf8\") as json_file:\n",
    "    EU_map = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наступний крок - створення інтерактивної карти за допомогою plotly.express.choropleth (). **[plotly.express.choropleth()](https://plotly.com/python/mapbox-county-choropleth/)**.  Як  вхідні параметри, ми повинні надіслати:\n",
    "\n",
    "1. Полігони країн: geojson = EU_map,\n",
    "2. Поля порівняння країн у наборі даних: locations = 'location',\n",
    "3. Поле ключа у файлі json, яке буде порівняно з адресами: featureidkey = 'properties.name',\n",
    "4. Колір країн: color = 'total_cases',\n",
    "5. Інформація для легенди: hover_name = 'location', hover_data = ['location', 'total_cases'],\n",
    "6. Поле анімації: animation_frame = 'Дата',\n",
    "7. Колірна гамма: color_continuous_scale = px.colors.diverging.RdYlGn [::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    modified_confirmed_EU[::-1],\n",
    "    geojson=EU_map,\n",
    "    locations='location',\n",
    "    featureidkey='properties.name',    \n",
    "    color= 'total_cases', \n",
    "    scope='europe',\n",
    "    hover_name= 'location',\n",
    "    hover_data= ['location', 'total_cases'],\n",
    "    animation_frame= 'Date', \n",
    "    color_continuous_scale=px.colors.diverging.RdYlGn[::-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потім ми повинні змінити деякі особливості карти. Наприклад: showcountries, showcoastline, showland, fitbouns у функції: plotly.express.update_geos ()  plotly.express.update_layout **[plotly.express.update_geos()](https://plotly.com/python/map-configuration/)**\n",
    "Також ми можемо змінити макет карти: **[plotly.express.update_layout](https://plotly.com/python/creating-and-updating-figures/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.update_geos(showcountries=False, showcoastlines=False, showland=False, fitbounds=\"locations\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text =\"COVID-19 Spread EU\",\n",
    "    title_x = 0.5,\n",
    "    geo= dict(\n",
    "        showframe= False,\n",
    "        showcoastlines= False,\n",
    "        projection_type = 'equirectangular'\n",
    "    ),\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щоб показати карту, ми повинні зберегти її у *.html* -файлі та відкрити: **[plotly.express.write_html](https://plotly.github.io/plotly.py-docs/generated/plotly.io.write_html.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html('first_figure.html', auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "У цій лабораторній роботі ми навчилися будувати гіпотези для моделей прогнозування, перетворення наборів даних для моделей введення-виведення. Навчилися розподіляти набори даних на навчальні та тестові. Також було показано, як передбачити моделі часових рядів, використовуючи перетворення лагів. Наприкінці лабораторної роботи ми відобразили набір даних на динамічній інтерактивній карті у форматі * .html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Індивідуальне завдання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Для файлу даних по світу\n",
    "1. Реалізувати прогнозування поширення COVID-19 у групі скандинавських країн. Візуалізувати поширення на інтерактивній мапі.\n",
    "2. Реалізувати прогнозування поширення COVID-19 у групі  країн Benelux. Візуалізувати поширення на інтерактивній мапі.\n",
    "3. Реалізувати прогнозування поширення COVID-19 у групі  країн Європейського Союзу. Візуалізувати поширення на інтерактивній мапі.\n",
    "4. Реалізувати прогнозування поширення COVID-19 у групі  країн, що повністю розташовані на Аравійському півострові. Візуалізувати поширення на інтерактивній мапі.\n",
    "5. Реалізувати прогнозування поширення COVID-19 у групі  країн Південна Корея, Гонконг, Сінгапур, Тайвань. Візуалізувати поширення на інтерактивній мапі.\n",
    "6. Реалізувати прогнозування поширення COVID-19 у групі  країн Монголія, Китай і Вєтнам. Візуалізувати поширення на інтерактивній мапі.\n",
    "7. Реалізувати прогнозування поширення COVID-19 у групі  Африканських країн, що повністю лежать у північній півкулі. Візуалізувати поширення на інтерактивній мапі.\n",
    "8. Реалізувати прогнозування поширення COVID-19 у групі  Африканських країн, що повністю лежать у південній півкулі. Візуалізувати поширення на інтерактивній мапі. \n",
    "9. Реалізувати прогнозування поширення COVID-19 у групі країн Індія, Непал, Пакистан. Візуалізувати поширення на інтерактивній мапі.\n",
    "10. Реалізувати прогнозування поширення COVID-19 у групі країн Південної Америки. Візуалізувати поширення на інтерактивній мапі.\n",
    "11. Реалізувати прогнозування поширення COVID-19 у групі прибалтійських  країн. Візуалізувати поширення на інтерактивній мапі.\n",
    "12. Реалізувати прогнозування поширення COVID-19 у групі  балканських країн. Візуалізувати поширення на інтерактивній мапі.\n",
    "13. Реалізувати прогнозування поширення COVID-19 у групі країн Польща, Угорщина, Чехія, Словаччина, Словенія, Хорватія, Литва, Латвія й Естонія. Візуалізувати поширення на інтерактивній мапі.\n",
    "14. Реалізувати прогнозування поширення COVID-19 у групі країн Болгарія, Румунія, Україна, Албанія, Македонія. Візуалізувати поширення на інтерактивній мапі.\n",
    "15. Реалізувати прогнозування поширення COVID-19 у групі країн Канада, США, Мексика. Візуалізувати поширення на інтерактивній мапі.\n",
    "Для файлу даних по Україні\n",
    "1. Реалізувати прогнозування поширення COVID-19 у Волинській та Рівненській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "2. Реалізувати прогнозування поширення COVID-19 у Київській області та місті Київ. Візуалізувати поширення на інтерактивній мапі.\n",
    "3. Реалізувати прогнозування поширення COVID-19 у Закарпатській та Львівській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "4. Реалізувати прогнозування поширення COVID-19 у Івано-Франківській та Чернівецькій областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "5. Реалізувати прогнозування поширення COVID-19 у Волинській та Рівненській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "6.  Реалізувати прогнозування поширення COVID-19 у Львівській та Тернопільській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "7. Реалізувати прогнозування поширення COVID-19 у Львівській та Івано-Франківській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "8. Реалізувати прогнозування поширення COVID-19 у Львівській, Тернопільській та Івано-Франківській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "9. Реалізувати прогнозування поширення COVID-19 у Хмельницькій та Вінницькій. Візуалізувати поширення на інтерактивній мапі.\n",
    "10. Реалізувати прогнозування поширення COVID-19 у Черкаській та Кропивницькій, областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "11. Реалізувати прогнозування поширення COVID-19 у Волинській, Житомирській та Рівненській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "12. Реалізувати прогнозування поширення COVID-19 у Чернігівській та Сумській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "13. Реалізувати прогнозування поширення COVID-19 у Миколаївській та Одеській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "14. Реалізувати прогнозування поширення COVID-19 у Вінницькій та Черкаській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "15. Реалізувати прогнозування поширення COVID-19 у Харківській та Луганській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "16. Реалізувати прогнозування поширення COVID-19 у Дніпровській та Донецькій областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "17. Реалізувати прогнозування поширення COVID-19 у Запорізькій таХерсонській областях. Візуалізувати поширення на інтерактивній мапі.\n",
    "18. Реалізувати прогнозування поширення COVID-19 у Харківській, Полтавській та Сумській областях. Візуалізувати поширення на інтерактивній мапі.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Yaroslav Vyklyuk, prof., PhD., DrSc](http://vyklyuk.bukuniver.edu.ua/en/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
